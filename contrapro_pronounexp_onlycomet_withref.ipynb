{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7792886,"sourceType":"datasetVersion","datasetId":4561890},{"sourceId":8072010,"sourceType":"datasetVersion","datasetId":4763033},{"sourceId":8564952,"sourceType":"datasetVersion","datasetId":5103826}],"dockerImageVersionId":30665,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\n\nimport os\n\n# Specify the directory path\ndirectory_path = '/kaggle/working/reward_plots'\n\n# Create the directory\nos.makedirs(directory_path, exist_ok=True)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dependencies which require restarting \n!pip install trl\n%pip install -U datasets\n!pip install unbabel-comet\n!pip install pyarrow==11.0.0\n\nfrom huggingface_hub import notebook_login\nnotebook_login()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%env TOKENIZERS_PARALLELISM=false","metadata":{"execution":{"iopub.status.busy":"2024-08-11T06:47:37.774298Z","iopub.execute_input":"2024-08-11T06:47:37.774992Z","iopub.status.idle":"2024-08-11T06:47:37.789116Z","shell.execute_reply.started":"2024-08-11T06:47:37.774954Z","shell.execute_reply":"2024-08-11T06:47:37.787796Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"env: TOKENIZERS_PARALLELISM=false\n","output_type":"stream"}]},{"cell_type":"code","source":"# Importing dependencies\nimport pandas as pd\nimport torch\nimport numpy as np\nfrom transformers import NllbTokenizerFast, TrainingArguments, AutoModelForSeq2SeqLM\nfrom trl import PPOTrainer, PPOConfig, create_reference_model\nfrom datasets import Dataset\nimport warnings\nimport matplotlib.pyplot as plt\nwarnings.filterwarnings(\"ignore\")\nfrom collections import deque\nfrom datasets import load_dataset\nfrom trl import IterativeSFTTrainer\nfrom comet import download_model, load_from_checkpoint\nimport statistics\nimport torch.nn.functional as F\nimport logging\nloggers = [logging.getLogger(name) for name in logging.root.manager.loggerDict]\nfor logger in loggers:\n    logger.setLevel(logging.WARNING)\n\n# Setting device to GPU\ndevice = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n\n#Loading reward generation model\nmodel_path = download_model(\"Unbabel/wmt22-comet-da\")\nreward_gen_model = load_from_checkpoint(model_path)","metadata":{"execution":{"iopub.status.busy":"2024-08-11T06:47:39.745736Z","iopub.execute_input":"2024-08-11T06:47:39.746083Z","iopub.status.idle":"2024-08-11T06:48:32.375087Z","shell.execute_reply.started":"2024-08-11T06:47:39.746058Z","shell.execute_reply":"2024-08-11T06:48:32.373943Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2024-08-11 06:47:48.373024: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-08-11 06:47:48.373190: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-08-11 06:47:48.509372: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b82ed4ee98749bc83756aebadaa7e4e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":".gitattributes:   0%|          | 0.00/1.48k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e9db2ca235744ed583d35a22983e6ad9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"LICENSE:   0%|          | 0.00/9.69k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8e4c15c0469842c6b191a30d3d55b3d7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/3.53k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2d09c201bc754b07b190b605f00c2797"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"hparams.yaml:   0%|          | 0.00/567 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"284bdeec4a684e29a4c3bf7fd16effa3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.ckpt:   0%|          | 0.00/2.32G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e1cf5b29fd4462c9cf025f04597d754"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"612ceaaa84184ed18fab0d509e7c0ad2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"713bbe1b108a46b694b7b4a5525cc661"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"53cf5bc279c340388f9af141e6d20b95"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/616 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0bae0605d855432b9f10302f6d5a8d4f"}},"metadata":{}}]},{"cell_type":"code","source":"# Reward functions\ndef gen_hf(data,token_length):\n    data_comet_inp = []\n    for i in range(len(data)):\n        data_comet = {}\n        data_comet[\"mt\"]=data[i][\"mt\"]\n        data_comet[\"src\"]=data[i][\"src\"]\n        data_comet[\"ref\"]=data[i][\"ref\"]\n        data_comet_inp.append(data_comet)\n    output = reward_gen_model.predict(data_comet_inp,batch_size = len(data), gpus = 1,progress_bar=False)\n    rewards = output.scores\n    #print(\"Comet rewards: \",rewards)\n    pro_rew = []\n    #here \n    for i in range(len(data)):\n        pro_rew.append(data[i][\"pro\"])\n    #print(\"Pronoun rewards: \",pro_rew)\n    final_reward = [0]*len(rewards)\n    for i in range(len(final_reward)):\n        #final_reward[i] = rewards[i] + (pro_rew[i]/token_length)\n        final_reward[i] = rewards[i] \n    # /20 \n    # /(No of tokens in the sentence)\n    # Discard sentences with length <= 5 in training set \n    #print(\"\\n\")\n    #print(\"Final rewards: \",final_reward)    \n    high_ind = np.argmax(final_reward)\n    y_high = data[high_ind][\"mt\"]\n    return y_high, high_ind\n\ndef calc_comet_score(data):\n    output = reward_gen_model.predict(data,batch_size = len(data), gpus = 1,progress_bar=False)\n    rewards = output.scores\n    print(\"COMET reward: \",rewards[0])\n    return rewards[0]\n\ndef calc_val_comet_score(data):\n    output = reward_gen_model.predict(data,batch_size = len(data), gpus = 1,progress_bar=False)\n    rewards = output.scores\n    return sum(rewards)/len(rewards)\n\npronoun_data = pd.read_csv(\"/kaggle/input/contrapro-extracted-data/pronouns_data.csv\")\n\n\ndef get_pronoun_reward(response,k):\n    pro_reward = 0\n    for i in range(len(response.sequences[0])):\n        token = tokenizer.decode(response.sequences[0][i])\n        if token == pronoun_data[\"ref pronoun\"].iloc[k] or token == pronoun_data[\"replacement1\"].iloc[k] or token == pronoun_data[\"replacement2\"].iloc[k] or token == pronoun_data[\"replacement3\"].iloc[k]:\n            probabilities_tensor = torch.nn.functional.softmax(response.scores[i-1], dim=-1)\n            max_prob_index = torch.argmax(probabilities_tensor)\n            max_prob_value = probabilities_tensor.flatten()[max_prob_index]\n            if token == pronoun_data[\"ref pronoun\"].iloc[k]:\n                pro_reward = max_prob_value.item()\n            else:\n                pro_reward = -max_prob_value.item()\n    return pro_reward\n\n\ndef calc_pronoun_score(responses):\n    pro_reward = [0]*(len(responses))\n    k = -84\n    for i in range(len(responses)):\n        for j in range(len(responses[i].sequences[0])):\n            token = tokenizer.decode(responses[i].sequences[0][j])\n            if token == pronoun_data[\"ref pronoun\"].iloc[k] or token == pronoun_data[\"replacement1\"].iloc[k] or token == pronoun_data[\"replacement2\"].iloc[k] or token == pronoun_data[\"replacement3\"].iloc[k]:\n                probabilities_tensor = torch.nn.functional.softmax(responses[i].scores[j-1], dim=-1)\n                max_prob_index = torch.argmax(probabilities_tensor)\n                max_prob_value = probabilities_tensor.flatten()[max_prob_index]\n                if token == pronoun_data[\"ref pronoun\"].iloc[k]:\n                    pro_reward[i] = max_prob_value.item()\n                else:\n                    pro_reward[i] = -max_prob_value.item()\n        k = k + 1\n    return pro_reward","metadata":{"execution":{"iopub.status.busy":"2024-08-11T06:48:32.377670Z","iopub.execute_input":"2024-08-11T06:48:32.377953Z","iopub.status.idle":"2024-08-11T06:48:32.415957Z","shell.execute_reply.started":"2024-08-11T06:48:32.377918Z","shell.execute_reply":"2024-08-11T06:48:32.415061Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"'''\nimport re\n# Load the CSV files\nsrc_df = pd.read_csv('/kaggle/input/pronouns-data-final/src_sents_data_with_context.csv',encoding = \"latin-1\")\ntgt_df = pd.read_csv('/kaggle/input/pronouns-data-final/tgt_sents_data.csv',encoding = \"latin-1\")\n\n# Ensure the files have the same number of entries\nassert len(src_df) == len(tgt_df), \"The source and target files do not have the same number of entries.\"\n\ndef extract_source_sentence(context):\n    match = re.search(r'</context>(.*)', context)\n    if match:\n        return match.group(1).strip()\n    return \"\"\n\ndef count_words(sentence):\n    return len(sentence.split())\n\n# Apply the extraction function\nsrc_df['source_sentence'] = src_df['src segment'].apply(extract_source_sentence)\n\n\n# Filter based on the length of the source sentence\nfiltered_src_df = src_df[src_df['source_sentence'].apply(count_words) > 5]\n\n# Get the indices of the filtered source sentences\nfiltered_indices = filtered_src_df.index\n\n# Filter the target sentences based on the filtered source sentences\nfiltered_tgt_df = tgt_df.loc[filtered_indices]\nfiltered_pronoun_df = pronoun_data.loc[filtered_indices]\n\n# Drop the temporary 'source_sentence' column\nfiltered_src_df = filtered_src_df.drop(columns=['source_sentence'])\n\n# Save the filtered data to new CSV files\nfiltered_src_df.to_csv('/kaggle/working/filtered_source_sentences_fini.csv', index=False)\nfiltered_tgt_df.to_csv('/kaggle/working/filtered_target_sentences_fini.csv', index=False)\nfiltered_pronoun_df.to_csv('/kaggle/working/filtered_pronoun_data_fini.csv', index=False)\n\nprint(\"Filtered CSV files have been saved successfully.\")\n'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/nllb-200-distilled-600M\",token=True)\ntokenizer = NllbTokenizerFast.from_pretrained(\"facebook/nllb-200-distilled-600M\",token=True, src_lang = \"eng_Latn\", tgt_lang=\"deu_Latn\",use_fast=\"False\")\n#tokenizer_rev = NllbTokenizerFast.from_pretrained(\"facebook/nllb-200-distilled-600M\",token=True, src_lang = \"deu_Latn\", tgt_lang=\"eng_Latn\",use_fast=\"False\")\nif tokenizer.pad_token is None:\n    tokenizer.pad_token = tokenizer.eos_token\n\n# Reading europal dataset for ENGLISH ====> GERMAN\n# Preprocess data\n\n#here\nf = pd.read_csv(\"/kaggle/input/contrapro-extracted-data/src_sents_data.csv\")\ng = pd.read_csv(\"/kaggle/input/contrapro-extracted-data/tgt_sents_data.csv\")\n\n#f = open(\"/kaggle/input/europarl-nozip/europarl-v7.de-en.en\")\n#g = open(\"/kaggle/input/europarl-nozip/europarl-v7.de-en.de\")\n\n#here\nsrc_sents = f.iloc[:,0].tolist()\ntgt_sents = g.iloc[:,0].tolist()\n\n#src_sents = f.readlines()\n#tgt_sents = g.readlines()","metadata":{"execution":{"iopub.status.busy":"2024-08-11T06:48:32.417273Z","iopub.execute_input":"2024-08-11T06:48:32.417503Z","iopub.status.idle":"2024-08-11T06:48:49.312558Z","shell.execute_reply.started":"2024-08-11T06:48:32.417468Z","shell.execute_reply":"2024-08-11T06:48:49.311673Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/846 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f15b87e4872c42ddac8205a90f262783"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/2.46G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b13f1222c2aa46de9bb68ed6aa022215"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/189 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0aee08b6f2cd4d5a9acb97f35f97e68e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/564 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e9bac7c9820455d9ef2156f875e4b29"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentencepiece.bpe.model:   0%|          | 0.00/4.85M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b9b8811196124f9ca7416c4f0f78d4dc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.3M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e1b405ddd154f05b6f38534d652523f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/3.55k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f82ed469861d46e59867d08afab2bf9e"}},"metadata":{}}]},{"cell_type":"code","source":"print(len(src_sents))\nprint(len(tgt_sents))","metadata":{"execution":{"iopub.status.busy":"2024-08-11T06:48:49.315459Z","iopub.execute_input":"2024-08-11T06:48:49.316110Z","iopub.status.idle":"2024-08-11T06:48:49.321056Z","shell.execute_reply.started":"2024-08-11T06:48:49.316072Z","shell.execute_reply":"2024-08-11T06:48:49.320205Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"12000\n12000\n","output_type":"stream"}]},{"cell_type":"code","source":"# Loading transformer\nVAL_SIZE = 84\ntrain_src = src_sents[:-VAL_SIZE]\nval_src = src_sents[-VAL_SIZE:]\ntrain_tgt = tgt_sents[:-VAL_SIZE]\nval_tgt = tgt_sents[-VAL_SIZE:]\nvalid_data = pd.DataFrame({'src_sents':train_src, 'tgt_sents':train_tgt})\nBATCH_SIZE = 4\nvalid_data_hf = Dataset.from_pandas(valid_data)\ndef collator(data):\n    return dict((key, [d[key] for d in data]) for key in data[0])\n\n#Preprocess validation set\nvalidation = pd.DataFrame({'src_sents':val_src, 'tgt_sents':val_tgt})\n","metadata":{"execution":{"iopub.status.busy":"2024-08-11T06:48:50.438062Z","iopub.execute_input":"2024-08-11T06:48:50.438368Z","iopub.status.idle":"2024-08-11T06:48:50.499727Z","shell.execute_reply.started":"2024-08-11T06:48:50.438336Z","shell.execute_reply":"2024-08-11T06:48:50.498431Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"import re \n\n# Training loop\n# Loading model parameters and initialising trainer\n# model_ref = create_reference_model(model)\ndevice=\"cuda\"\nmodel = model.to(device)\nmodel_ref = model.to(device)\ndataloader = torch.utils.data.DataLoader(valid_data_hf, batch_size=BATCH_SIZE, shuffle=False, collate_fn = collator)\nsteps = 0\nite = 0\nrewards = []\nplot_s_reward = []\nplot_p_reward = []\navg_rew = deque(maxlen=15)\navg_s_rew_dq = deque(maxlen=15)\navg_p_rew_dq = deque(maxlen=15)\navg_s_rew = []\navg_p_rew = []\navg_rew2 = []\nplot_pb_reward = []\nplot_m_reward = []\navg_pb_rew_dq = deque(maxlen=15)\navg_m_rew_dq = deque(maxlen=15)\navg_pb_rew = []\navg_m_rew = []\ntraining_args = TrainingArguments(\n    per_device_train_batch_size=4, \n    gradient_accumulation_steps=16,\n    output_dir=\"/kaggle/working/\",\n    learning_rate=6e-6,\n    overwrite_output_dir=True,\n    max_steps=1000,\n    gradient_checkpointing=True,\n    optim=\"adafactor\",\n    report_to=\"none\",\n    save_strategy=\"no\",\n    logging_strategy=\"no\",\n    logging_steps=None\n)\nval_scores = []\nval_pronoun_scores = []\nno_of_positives = []\ntrainer = IterativeSFTTrainer(model=model,args=training_args,tokenizer=tokenizer)\nimport os\nos.environ['WANDB_DISABLED'] = 'true' \n\nfor sample in dataloader:\n    ite += 1\n    sample_high = []\n    sample_label = []\n    print(\"###############################################\")\n    print(\"Batch no: \",ite)\n    print(\"\\n\")\n    query = tokenizer(sample[\"src_sents\"],return_tensors=\"pt\",padding=True,truncation=True).input_ids.to(device)\n    batch_reward = []\n    batch_pronoun_reward = []\n    input_query_list = []\n    input_responses_list = []\n    avg_reward = []\n    #print(\"Source\",sample[\"src_sents\"])\n    is_pro_correct = 0\n    for j in range(BATCH_SIZE):\n        print(\"Sample no: \",j+1)\n        rew = []\n        unique_translations = []\n        pronoun_reward = []\n        it = 0\n        \n        '''match = re.search(r'</context>(.*)', sample[\"src_sents\"][j])\n        if match:\n            relevant_text = match.group(1).strip()\n        else:\n            raise ValueError(\"The provided text does not contain '</context>'\")\n        \n        token_length = len(tokenizer.tokenize(relevant_text))\n        '''\n        \n        token_length = len(tokenizer.tokenize(sample[\"src_sents\"][j]))\n        while len(unique_translations)<10:\n            it = it + 1\n            if it>=25 and len(unique_translations)<4:\n                break\n            if it>=50:\n                break\n            response = model.generate(\n                    tokenizer(sample[\"src_sents\"][j],return_tensors=\"pt\",padding=True,truncation=True).input_ids.to(device),\n                    forced_bos_token_id=tokenizer.lang_code_to_id[\"deu_Latn\"],\n                    do_sample = True,\n                    num_beams= 1,\n                    return_dict_in_generate=True, \n                    output_scores=True\n                    )\n            translation = tokenizer.decode(response.sequences[0], skip_special_tokens=True)\n            #here\n            pronoun_reward.append(get_pronoun_reward(response,j+(4*(ite-1))))\n            # print(response.scores)\n            flag = True\n            for i in unique_translations:\n                if translation == i:\n                    #here\n                    pronoun_reward = pronoun_reward[:-1]\n                    flag = False\n            if flag:\n                unique_translations.append(translation)\n        inp_ref = []\n        inp_src = []\n        for i in range(len(unique_translations)):\n            inp_ref.append(sample[\"tgt_sents\"][j])\n            inp_src.append(sample[\"src_sents\"][j])\n        comet_input = []\n        #print(\"Refs\",sample[\"tgt_sents\"][j])\n        for i in range(len(unique_translations)):\n            data = {}\n            data[\"mt\"]=unique_translations[i]\n            data[\"src\"]=sample[\"src_sents\"][j]\n            #here\n            data[\"pro\"]=pronoun_reward[i]\n            data[\"ref\"]=sample[\"tgt_sents\"][j]\n            comet_input.append(data)                                                                                                                                                                \n        #print(comet_input)\n        y_high, ind_best= gen_hf(comet_input,token_length)\n\n        #Train Reward Plot\n        model_best_response = model.generate(\n                    tokenizer(sample[\"src_sents\"][j],return_tensors=\"pt\",padding=True,truncation=True).input_ids.to(device),\n                    forced_bos_token_id=tokenizer.lang_code_to_id[\"deu_Latn\"],\n                    do_sample = True,\n                    top_k=5,\n                    return_dict_in_generate=True, \n                    output_scores=True\n        )\n        \n        translation = tokenizer.decode(model_best_response.sequences[0],skip_special_tokens=True)\n        #here\n        pro_rew = get_pronoun_reward(model_best_response,j+(4*(ite-1)))\n        '''\n        if steps%25 == 0:\n            print(f\"For sent {j} in batch: \")\n            print(\"Source sentence with context: \",sample[\"src_sents\"][j])\n            print(\"Source sentence without context: \",relevant_text)\n            print(\"Best candidate translation: \",unique_translations[ind_best])\n            print(\"Best translation for plot: \",translation)\n            print(\"Ref (actual) translation: \",sample[\"tgt_sents\"][j])\n            print(\"Pronoun reward: \",pro_rew)\n        '''\n        comet_input = []\n        data = {}\n        data[\"mt\"] = translation\n        #data[\"src\"] = relevant_text\n        data[\"src\"] = sample[\"src_sents\"][j]\n        data[\"ref\"] = sample[\"tgt_sents\"][j]\n        comet_input.append(data)\n        highest = calc_comet_score(comet_input)\n        plot_p_reward.append(pro_rew)\n        plot_s_reward.append(highest)\n        avg_p_rew_dq.append(pro_rew)\n        avg_s_rew_dq.append(highest)\n        avg_p_rew.append(np.mean(avg_p_rew_dq))\n        avg_s_rew.append(np.mean(avg_s_rew_dq))\n        batch_pronoun_reward.append(pro_rew)\n        batch_reward.append(highest)\n        sample_high.append(y_high)\n        print(\"\\n\")\n    sample_src = sample['src_sents']\n    mean_r = np.mean(batch_reward)\n    mean_p = np.mean(batch_pronoun_reward)\n    #print(\"Batch mean train reward: \",mean_r)\n    #print(\"Batch mean pronoun train reward: \",mean_p)\n    plot_m_reward.append(mean_r)\n    plot_pb_reward.append(mean_p)\n    avg_m_rew_dq.append(mean_r)\n    avg_pb_rew_dq.append(mean_p)\n    avg_m_rew.append(np.mean(avg_m_rew_dq))\n    avg_pb_rew.append(np.mean(avg_pb_rew_dq))\n    trainer.step(texts=sample_src,texts_labels=sample_high)\n    steps+=1\n    print(\"###############################################\")\n    print(\"\\n\")\n    if steps==1 or steps%100==0:\n        print(\"#########################################################\")\n        print(\"Performing Validation\")\n        print(\"#########################################################\")\n        src_sents = validation[\"src_sents\"].tolist()\n        tgt_sents = validation[\"tgt_sents\"].tolist()\n        translations = []\n        best_responses = []\n        src_wo_context = []\n        for i in range(VAL_SIZE):\n            '''\n            match = re.search(r'</context>(.*)', src_sents[i])\n            if match:\n                relevant_text = match.group(1).strip()\n            else:\n                raise ValueError(\"The provided text does not contain '</context>'\")\n            src_wo_context.append(relevant_text)\n            '''\n            src_wo_context.append(src_sents[i])\n            val_query = tokenizer(src_sents[i],return_tensors=\"pt\",padding=True,truncation=True).input_ids.to(device)\n            model_best_response = model.generate(\n                    val_query,\n                    forced_bos_token_id=tokenizer.lang_code_to_id[\"deu_Latn\"],\n                    do_sample = True,\n                    top_k=5,\n                    return_dict_in_generate=True, \n                    output_scores=True\n                    )\n            translations.append(tokenizer.decode(model_best_response.sequences[0], skip_special_tokens=True))\n            best_responses.append(model_best_response)\n        comet_input = []\n        for i in range(len(validation)):\n            data = {}\n            data[\"mt\"] = translations[i]\n            data[\"src\"] = src_wo_context[i]\n            data[\"ref\"] = tgt_sents[i]\n            comet_input.append(data)\n        val_mean_score = calc_val_comet_score(comet_input)\n        #here\n        \n        pronoun_scores = calc_pronoun_score(best_responses)\n        val_mean_pronoun_score = sum(pronoun_scores)/len(pronoun_scores)\n        val_pronoun_scores.append(val_mean_pronoun_score)\n        pos = 0\n        for i in pronoun_scores:\n            if i > 0:\n                pos += 1\n        no_of_positives.append(pos)    \n        print(\"Current validation pronoun scores are: \\n\",val_pronoun_scores)\n        print(\"No of correct pronouns chosen are: \\n\",no_of_positives)\n        \n        val_scores.append(val_mean_score)\n        print(\"Current validation Comet scores are: \\n\",val_scores)\n        \n\n    if (steps)%25==0:\n        plt.plot(plot_s_reward,'b',label='Comet reward', alpha = 0.2)\n        plt.plot(avg_s_rew,'r',label='Moving average (over last 15 samples)')\n        plt.xlabel(f\"No of samples\")\n        plt.ylabel(\"Samplewise Comet Training Reward\")\n        plt.legend()\n        plt.savefig(f\"/kaggle/working/reward_plots/Sample_comet_reward_{steps}_t5.png\")\n        plt.show()\n        plt.clf()\n        \n        plt.plot(plot_p_reward,'b',label='Pronoun reward', alpha = 0.2)\n        plt.plot(avg_p_rew,'r',label='Moving average (over last 15 samples)')\n        plt.xlabel(f\"No of samples\")\n        plt.ylabel(\"Samplewise Pronoun Training Reward\")\n        plt.legend()\n        plt.savefig(f\"/kaggle/working/reward_plots/Sample_pronoun_reward_{steps}_t5.png\")\n        plt.show()\n        plt.clf()\n        \n        plt.plot(plot_pb_reward,'b',label='Pronoun reward', alpha = 0.2)\n        plt.plot(avg_pb_rew,'r',label='Moving average (over last 15 samples)')\n        plt.xlabel(f\"No of batches\")\n        plt.ylabel(\"Batchwise Pronoun Training Reward\")\n        plt.legend()\n        plt.savefig(f\"/kaggle/working/reward_plots/Batch_pronoun_reward_{steps}_t5.png\")\n        plt.show()\n        plt.clf()\n        \n        plt.plot(plot_m_reward,'b',label='Comet reward',alpha = 0.2)\n        plt.plot(avg_m_rew,'r',label='Moving average (over last 15 samples)')\n        plt.xlabel(f\"No of batches\")\n        plt.ylabel(\"Batchwise Comet Training Reward\")\n        plt.legend()\n        plt.savefig(f\"/kaggle/working/reward_plots/Batch_comet_reward_{steps}_t5.png\")\n        plt.show()\n        plt.clf()\n        print(\"Current validation Comet scores are: \\n\",val_scores)\n    if (steps)==750 or steps==1000:\n        trainer.push_to_hub(f\"satanicmangoes/RAFT+_nllb_{steps}\")\n        break","metadata":{"execution":{"iopub.status.busy":"2024-08-11T06:48:50.501655Z","iopub.execute_input":"2024-08-11T06:48:50.501862Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"the `lang_code_to_id` attribute is deprecated. The logic is natively handled in the `tokenizer.adder_tokens_decoder` this attribute will be removed in `transformers` v4.38\n","output_type":"stream"},{"name":"stdout","text":"###############################################\nBatch no:  1\n\n\nSample no:  1\nCOMET reward:  0.7840127348899841\n\n\nSample no:  2\nCOMET reward:  0.7659068703651428\n\n\nSample no:  3\nCOMET reward:  0.5129714012145996\n\n\nSample no:  4\nCOMET reward:  0.4739450514316559\n\n\n###############################################\n\n\n#########################################################\nPerforming Validation\n#########################################################\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}